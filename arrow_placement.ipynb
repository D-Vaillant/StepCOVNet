{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras.layers import Dropout, Dense, Flatten, BatchNormalization, LSTM, Input, concatenate\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Nadam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 4)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.ones((10,4))\n",
    "data[1] = np.zeros((1, 4))\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6, 5, 4), (6, 3))"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.util import ngrams\n",
    "look_back = 5\n",
    "output = np.asarray(list(ngrams(data, look_back)))\n",
    "tok = np.zeros((6,3))\n",
    "output.shape, tok.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 15)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.zeros((output.shape[0], 15))\n",
    "y[:,0] = 1\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build():\n",
    "    \"\"\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(10, \n",
    "                   input_shape=input_shape[1],\n",
    "                   return_sequences = False))\n",
    "    model.add(LSTM(10, return_sequences = True))\n",
    "    model.add(LSTM(10))\n",
    "    model.add(Dense(15, activation='softmax')) # 15 different types of note combinations (0000 is removed)\"\"\"\"\"\n",
    "    arrows = Input(shape = (5,4,))\n",
    "    tokens = Input(shape = (3,))\n",
    "    x = LSTM(10, return_sequences = True)(arrows)\n",
    "    x = LSTM(10, return_sequences = True)(x)\n",
    "    x = LSTM(10)(x)\n",
    "    x = Model(inputs = arrows, outputs = x)\n",
    "    y = Dense(1, activation = \"relu\")(tokens)\n",
    "    y = Model(inputs = tokens, outputs = y)\n",
    "    combined = concatenate([x.output, y.output])\n",
    "    z = Dense(15, activation = \"softmax\")(combined)\n",
    "    model = Model(inputs = [x.input, y.input], outputs = z)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='Nadam', metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 5, 4)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_27 (LSTM)                  (None, 5, 10)        600         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_28 (LSTM)                  (None, 5, 10)        840         lstm_27[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 3)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_29 (LSTM)                  (None, 10)           840         lstm_28[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 1)            4           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 11)           0           lstm_29[0][0]                    \n",
      "                                                                 dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 15)           180         concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 2,464\n",
      "Trainable params: 2,464\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "6/6 [==============================] - 4s 652ms/step - loss: 2.6549 - acc: 0.8333\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 2.5398 - acc: 1.0000\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 2.3466 - acc: 1.0000\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 1.9894 - acc: 1.0000\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 1.3709 - acc: 1.0000\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.6783 - acc: 1.0000\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.2809 - acc: 1.0000\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.1336 - acc: 1.0000\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0791 - acc: 1.0000\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0571 - acc: 1.0000\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0466 - acc: 1.0000\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0408 - acc: 1.0000\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.0370 - acc: 1.0000\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.0338 - acc: 1.0000\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.0313 - acc: 1.0000\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.0292 - acc: 1.0000\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0273 - acc: 1.0000\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.0256 - acc: 1.0000\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.0241 - acc: 1.0000\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0227 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fe3c3f7ef0>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 1\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Nadam', metrics=['accuracy'])\n",
    "model.fit([output, tok], \n",
    "          y,\n",
    "          epochs = 20,\n",
    "          batch_size= batch_size,\n",
    "          verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
